{"metadata":{"colab":{"collapsed_sections":["-P4bFeekl4Gs","ajqV8vMa_61H"],"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Make simulate data faster using just a unique estimation for each run, and not estimate each time just a single number.","metadata":{"id":"MwKx7jjPD-hG"}},{"cell_type":"markdown","source":"# Set Up","metadata":{"id":"sYyC7sc68TCL"}},{"cell_type":"code","source":"!git clone https://github.com/nudojacopo/thesis.git","metadata":{"execution":{"iopub.status.busy":"2024-06-24T07:11:21.165298Z","iopub.execute_input":"2024-06-24T07:11:21.165690Z","iopub.status.idle":"2024-06-24T07:11:28.539267Z","shell.execute_reply.started":"2024-06-24T07:11:21.165659Z","shell.execute_reply":"2024-06-24T07:11:28.537873Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'thesis'...\nremote: Enumerating objects: 1011, done.\u001b[K\nremote: Counting objects: 100% (260/260), done.\u001b[K\nremote: Compressing objects: 100% (73/73), done.\u001b[K\nremote: Total 1011 (delta 191), reused 249 (delta 187), pack-reused 751\u001b[K\nReceiving objects: 100% (1011/1011), 53.84 MiB | 14.57 MiB/s, done.\nResolving deltas: 100% (634/634), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nroot='/kaggle/working/'\nimport sys\nmodule_path = root+'thesis/src/HWK'\nsys.path.append(module_path)\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport seaborn as sns\nfrom scipy import stats\nimport random\nfrom scipy.stats import chi2\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom statsmodels.graphics.gofplots import qqplot","metadata":{"id":"EZnf35gtVNeL","outputId":"47e99e93-1635-4163-a816-5901e9af03ae","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-06-24T07:11:28.541974Z","iopub.execute_input":"2024-06-24T07:11:28.542450Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from HWK_package.functions import *","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import Data","metadata":{}},{"cell_type":"code","source":"!pip install gdown","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gdown\n\nurl='https://drive.google.com/uc?id=1fZZefnIvOve2aU9Fg0WGDXncMooQaorA'\n\noutput='facebook.csv'/kaggle\n\ngdown.download(url,output,quiet=False)\n\nurl='https://drive.google.com/uc?id=1CYe5nbgFLDgRa7ugsZxOOxLjizQbgFii'\n\noutput='reddit.csv'\n\ngdown.download(url,output,quiet=False)\n\nurl='https://drive.google.com/uc?id=1K6uRHnR9ZT3k18Ip8jYqIRrrccWFxM03'\n\noutput='youtube.csv'\n\ngdown.download(url,output,quiet=False)\n\nurl='https://drive.google.com/uc?id=1wvPVrEDGvOX6LO-5Of-LuFyGJ8fI9jEN'\n\noutput='voat.csv'\n\ngdown.download(url,output,quiet=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model simulation","metadata":{"id":"kE_osuLe6pVR"}},{"cell_type":"code","source":"rd=pd.read_csv('/kaggle/working/reddit.csv')\nfb=pd.read_csv('/kaggle/working/facebook.csv')\nvo=pd.read_csv('/kaggle/working/voat.csv')\nyt=pd.read_csv('/kaggle/working/youtube.csv')","metadata":{"id":"Xyo2EwtM66Dn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fb = fb[fb['temporal_distance_birth_h'] < 100].copy()\nfb['temporal_distance_birth_base_100h'] = fb['temporal_distance_birth_h'] / 100\n\nrd = rd[rd['temporal_distance_birth_h'] < 100].copy()\nrd['temporal_distance_birth_base_100h'] = rd['temporal_distance_birth_h'] / 100\n\nvo = vo[vo['temporal_distance_birth_h'] < 100].copy()\nvo['temporal_distance_birth_base_100h'] = vo['temporal_distance_birth_h'] / 100\nvo['post_id'] = vo['root_submission']\nvo['user_id']=vo['user']\n\nyt = yt[yt['temporal_distance_birth_h'] < 100].copy()\nyt['temporal_distance_birth_base_100h'] = yt['temporal_distance_birth_h'] / 100\nyt['user_id']=yt['user']","metadata":{"id":"0D2OOGmXA9c3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_intervals = np.arange(0, 1, 0.01)  # Utilizzo di np.arange per intervalli decimali\n\nfb_ECDF = calculate_ECDF(fb, time_intervals)\nfb_ECDF['Platform']='Facebook - News'\nrd_ECDF = calculate_ECDF(rd, time_intervals)\nrd_ECDF['Platform']='Reddit'\n\nvo_ECDF = calculate_ECDF(vo, time_intervals)\nvo_ECDF['Platform']='Voat'\n\nyt_ECDF = calculate_ECDF(yt, time_intervals)\nyt_ECDF['Platform']='yt'\n\ncombined_results = pd.concat([fb_ECDF, rd_ECDF,vo_ECDF,yt_ECDF], ignore_index=True)\n","metadata":{"id":"ZoIeWqGYAZTr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=combined_results\nplot_ECDF(df,level=99)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":718},"id":"njOhQNNMklV8","outputId":"3b7ea765-1e2a-466a-8051-0fb331e507e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Manual simulation","metadata":{"id":"f39aYHwO62Y2"}},{"cell_type":"markdown","source":"### Parameters FB","metadata":{"id":"-MzWxHhy4CCi"}},{"cell_type":"code","source":"# Define the number of threads\nn = 5000\n\n# Define the parameters dictionary\nparameters = {\n    \"a\": 0.3844295492882861,\n    \"b\": 294.47288219865607,\n    \"loc\": 0.0009999999999999998,\n    \"scale\": 33.07578198818712,\n    \"alpha\": 0.1,\n    \"lambda_\": 0.6,\n    \"c\": 0.8569866519794784,\n    \"d\": 12.556141099060724,\n    \"l\": -12.51922356410994,\n    \"s\": 11.830321259706352,\n    \"cf\": 0.6366573262621085,\n    \"df\": 8.374547547078375,\n    \"lf\": -2.5492637062724093,\n    \"sf\": 8.384974991111687\n}\n\n# Call the simulate_data function with the unpacked dictionary\nsimulated, observed = simulate_data(fb, **parameters, num_threads=n)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":324},"id":"y6jmZ2MMzpqK","outputId":"edcdccd1-3248-498e-8596-1e4fbd9ef5fb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_intervals = np.arange(0, 1, 0.01)  # Utilizzo di np.arange per intervalli decimali\n\nsimulated_ECDF = calculate_ECDF(simulated, time_intervals)\nsimulated_ECDF['Platform']='Simulated'\nobserved_ECDF = calculate_ECDF(observed, time_intervals)\nobserved_ECDF['Platform']='Observed'\n\nreddit_ECDF = calculate_ECDF(rd[rd['post_id'].isin(rd['post_id'].unique()[0:n])], time_intervals)\nreddit_ECDF['Platform']='Reddit'\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lf7iW-Bt0V9A","outputId":"922622a8-53d7-4924-f42f-0fc8bf62d54a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_results = pd.concat([simulated_ECDF, observed_ECDF], ignore_index=True)\nerror = calculate_loss(simulated_ECDF, observed_ECDF)\nprint('The error is equal to: ' + str(round(error, 2)))\nprint(len(simulated)/len( observed))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z4ley0Hx4ooC","outputId":"ea0b6a0e-7847-40d6-ff30-27411516ea44","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_results = pd.concat([simulated_ECDF, observed_ECDF,reddit_ECDF], ignore_index=True)\ndf=combined_results\n# Plotting lineplot for both Reddit and Facebook with confidence intervals\nplt.figure(figsize=(12, 8))\nsns.lineplot(data=df, x='Time Grid Value', y='Share',hue='Platform', errorbar=('ci', 99))\nplt.title('')\nplt.ylabel('Share')\nplt.xlabel('Lifetime')\nplt.grid(False)\nplt.legend(title='Platform')\nplt.show()\n# con a,b uguale a 0.8,20","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"id":"L1dEtSML0sU4","outputId":"a03096a7-39b2-452f-b689-0f9c774b76da","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Parameters YT","metadata":{"id":"uLjhK3JpaB_S"}},{"cell_type":"code","source":"# Define the number of threads\nn = 5000\n\n# Define the parameters dictionary\nparameters = {\n    \"a\": 0.5186615140672572,\n    \"b\": 1.7898387515641103,\n    \"loc\": 0.0009999999999999998,\n    \"scale\": 1.110437329330408,\n    \"alpha\": 0.3,\n    \"lambda_\": 0.6,\n    \"c\": 0.5663021409117182,\n    \"d\": 6.55831360057811,\n    \"l\": -1.9310083161118459,\n    \"s\": 8.819660178404714,\n    \"cf\": 0.4727340951603921,\n    \"df\": 36.56890893735914,\n    \"lf\": -2.171689637029706,\n    \"sf\": 0.23303035879717182\n}\n\n# Call the simulate_data function with the unpacked dictionary\nsimulated, observed = simulate_data(yt, **parameters, num_threads=n)\n","metadata":{"id":"_T5RoVriaFwI","outputId":"b586d3c2-a19f-4334-d115-bfce5bd2e12b","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simulated_ECDF = calculate_ECDF(simulated, time_intervals)\nsimulated_ECDF['Platform']='Simulated'\nobserved_ECDF = calculate_ECDF(observed, time_intervals)\nobserved_ECDF['Platform']='YouTube'\n\nreddit_ECDF = calculate_ECDF(fb[fb['post_id'].isin(fb['post_id'].unique()[0:n])], time_intervals)\nreddit_ECDF['Platform']='Facebook'\n\nyoutube_ECDF = calculate_ECDF(rd[rd['post_id'].isin(rd['post_id'].unique()[0:n])], time_intervals)\nyoutube_ECDF['Platform']='Reddit'\n\ncombined_results = pd.concat([simulated_ECDF, observed_ECDF], ignore_index=True)\n","metadata":{"id":"psrKw7D7aHaL","outputId":"641caf87-ada6-434b-b6e6-012b047ac6bb","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = calculate_loss(simulated_ECDF, observed_ECDF)\nprint('The error is equal to: ' + str(round(error, 2)))\nprint(len(simulated)/len( observed))","metadata":{"id":"I9fTF0IgaRHb","outputId":"6f2f1e2f-12ef-4a13-b669-72aa4c8a7ac6","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Concatenate all ECDF data into one DataFrame\ncombined_results = pd.concat([reddit_ECDF, observed_ECDF, simulated_ECDF, youtube_ECDF], ignore_index=True)\ncombined_results['Style']=combined_results['Platform']=='Simulated'\n# Plotting lineplot for all platforms with confidence intervals\nplt.figure(figsize=(12, 8))\nsns.lineplot(data=combined_results, x='Time Grid Value', y='Share', hue='Platform',errorbar=('ci', 99), style='Style')\nplt.title('')\nplt.ylabel('Share')\nplt.xlabel('Lifetime')\nplt.grid(False)\nplt.legend(title='Platform')\nplt.show()","metadata":{"id":"p0ZTWHVoaTOy","outputId":"98eec7a2-9fed-49af-b195-641f8c5e3532","colab":{"base_uri":"https://localhost:8080/","height":717},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Parameters Vo","metadata":{"id":"kgJ0Rw3EZejr"}},{"cell_type":"code","source":"# Define the number of threads\nn = 5000\n\n# Update 'post_id' field in 'vo'\nvo['post_id'] = vo['root_submission']\n\n# Define the parameters dictionary\nparameters = {\n    \"a\": 0.7683453768943135,\n    \"b\": 181.35859916908146,\n    \"loc\": 0.0009999999999999998,\n    \"scale\": 10.849357267138616,\n    \"alpha\": 0.36,\n    \"lambda_\": 0.14,\n    \"c\": 0.5597232846389999,\n    \"d\": 95.64624655862815,\n    \"l\": -0.21532560420550612,\n    \"s\": 0.14969610190277538,\n    \"cf\": 0.46474050827474,\n    \"df\": 32.24830809233218,\n    \"lf\": -0.07760638016101293,\n    \"sf\": 0.574117870175086\n}\n\n# Call the simulate_data function with the unpacked dictionary\nsimulated, observed = simulate_data(vo, **parameters, num_threads=n)\n","metadata":{"id":"kxSij770-bvp","outputId":"dff9e964-583a-40ca-c1bb-d5d3e900fff2","colab":{"base_uri":"https://localhost:8080/"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simulated_ECDF = calculate_ECDF(simulated, time_intervals)\nsimulated_ECDF['Platform']='Simulated'\nobserved_ECDF = calculate_ECDF(observed, time_intervals)\nobserved_ECDF['Platform']='Voat'\n\nreddit_ECDF = calculate_ECDF(fb[fb['post_id'].isin(fb['post_id'].unique()[0:n])], time_intervals)\nreddit_ECDF['Platform']='Facebook'\n\nyoutube_ECDF = calculate_ECDF(yt[yt['post_id'].isin(yt['post_id'].unique()[0:n])], time_intervals)\nyoutube_ECDF['Platform']='YouTube'\n\ncombined_results = pd.concat([simulated_ECDF, observed_ECDF], ignore_index=True)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vt4_wYbRZaJ4","outputId":"c4030a1e-6e2c-4e16-e1b8-f4dfd3069ca2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = calculate_loss(simulated_ECDF, observed_ECDF)\nprint('The error is equal to: ' + str(round(error, 2)))\nprint(len(simulated)/len( observed))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3e54cae-9874-4c90-83c9-6c34a3c9694a","id":"ma7k6KZuZmX0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Concatenate all ECDF data into one DataFrame\ncombined_results = pd.concat([reddit_ECDF, observed_ECDF, simulated_ECDF, youtube_ECDF], ignore_index=True)\ncombined_results['Style']=combined_results['Platform']=='Simulated'\n# Plotting lineplot for all platforms with confidence intervals\nplt.figure(figsize=(12, 8))\nsns.lineplot(data=combined_results, x='Time Grid Value', y='Share', hue='Platform',errorbar=('ci', 99), style='Style')\nplt.title('Distribution of Conversation Lifetime Across Percentiles')\nplt.ylabel('Lifetime (minutes)')\nplt.xlabel('Percentile')\nplt.grid(False)\nplt.legend(title='Platform')\nplt.show()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"outputId":"1eaf3ec2-867c-4f5e-b733-bc081e8f649a","id":"gSn8Uzd9ZmX2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Parameters RD","metadata":{"id":"X8G--4jm4EFl"}},{"cell_type":"code","source":"# Define the number of threads\nn = 5000\n\n# Define the parameters dictionary\nparameters = {\n    \"a\": 1.3208418726992361,\n    \"b\": 366274394.2558266,\n    \"loc\": 0.00043188573340450587,\n    \"scale\": 21377429.04281839,\n    \"alpha\": 0.6,\n    \"lambda_\": 0.6,\n    \"c\": 0.6069205391107709,\n    \"d\": 14.804821905854089,\n    \"l\": -0.06145338859442588,\n    \"s\": 5.865235905966762,\n    \"cf\": 0.5697079509462244,\n    \"df\": 3.122380555707551,\n    \"lf\": -1.0878713951321233,\n    \"sf\": 223.89075150295344\n}\n\n# Call the simulate_data function with the unpacked dictionary\nsimulated, observed = simulate_data(rd, **parameters, num_threads=n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"04YyI5ws4GsK","outputId":"ac14780f-be95-46ae-8a2c-32cc96213c2b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"simulated_ECDF = calculate_ECDF(simulated, time_intervals)\nsimulated_ECDF['Platform']='Simulated'\nobserved_ECDF = calculate_ECDF(observed, time_intervals)\nobserved_ECDF['Platform']='Reddit'\n\nreddit_ECDF = calculate_ECDF(fb[fb['post_id'].isin(fb['post_id'].unique()[0:n])], time_intervals)\nreddit_ECDF['Platform']='Facebook'\n\nyoutube_ECDF = calculate_ECDF(yt[yt['post_id'].isin(yt['post_id'].unique()[0:n])], time_intervals)\nyoutube_ECDF['Platform']='YouTube'\n\ncombined_results = pd.concat([simulated_ECDF, observed_ECDF], ignore_index=True)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_a5zmXg84aNO","outputId":"7f5f67d6-6de7-49b6-d58c-4c17d9ccdee6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = calculate_loss(simulated_ECDF, observed_ECDF)\nprint('The error is equal to: ' + str(round(error, 2)))\nprint(len(simulated)/len( observed))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hn1GllqN06Tu","outputId":"cd1d1efc-afbc-4ed0-9a9f-8dba2135fd68","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_results = pd.concat([reddit_ECDF, observed_ECDF,simulated_ECDF,youtube_ECDF], ignore_index=True)\ndf=combined_results\n# Plotting lineplot for both Reddit and Facebook with confidence intervals\nplt.figure(figsize=(12, 8))\nsns.lineplot(data=df, x='Time Grid Value', y='Share',hue='Platform', errorbar=('ci', 99))\nplt.title('Distribution of Conversation Lifetime Across Percentiles (Reddit vs Facebook)')\nplt.ylabel('Lifetime (minutes)')\nplt.xlabel('Percentile')\nplt.grid(False)\nplt.legend(title='Platform')\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":717},"id":"gDXJCq77GnSW","outputId":"38217893-d270-4756-9c01-14b675484038","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Grid Search","metadata":{"id":"RsmOeVaM3sFk"}},{"cell_type":"code","source":"'''import itertools\nimport pandas as pd\nimport numpy as np\n\n# Define the parameters for each platform\n\n\na=1.3208418726992361\nb=366274394.2558266\nloc=0.00043188573340450587\nscale=21377429.04281839\nalpha=0.6\nlambda_=0.6\nc=0.6\nd=14.804821905854089\nl=-0.06145338859442588\ns=5.865235905966762\n\ncf=0.5697079509462244\ndf=3.122380555707551\nlf=-1.0878713951321233\nsf=223.89075150295344\nfacebook_params = [1.3208418726992361, 366274394.2558266, 0.00043188573340450587,21377429.04281839,0.6,0.6,0.6,14.804821905854089,-0.06145338859442588,5.865235905966762,0.5697079509462244,3.122380555707551,-1.0878713951321233,223.89075150295344]\nreddit_params = [1.3208418726992361, 366274394.2558266, 0.00043188573340450587,21377429.04281839,0.6,0.6,0.6,14.804821905854089,-0.06145338859442588,5.865235905966762,0.5697079509462244,3.122380555707551,-1.0878713951321233,223.89075150295344]\n\n# Combine all parameters\nall_params = [facebook_params, reddit_params]\n\n# Initialize an empty list to store results\nresults = []\n\n# Time intervals (placeholder, to be defined)\ntime_intervals = np.arange(0, 1, 0.01)  # Using np.arange for decimal intervals\n\n# Loop over each parameter combination\nfor params in tqdm(all_params):\n    # Unpack the parameters\n    a, b, alpha, lambda_, loc, scale, c = params[:7]\n    d, l, s, cf, df, lf, sf = params[7:] \n\n    # Simulate synthetic data\n    simulated, observed = simulate_data(rd, a, b, loc, scale, alpha, lambda_, c, d, l, s, cf, df, lf, sf, num_threads=1,activate_tqdm=False)\n\n    # Calculate ECDFs\n    simulated_ECDF = calculate_ECDF(simulated, time_intervals)\n    simulated_ECDF['Platform'] = 'Simulated'\n    observed_ECDF = calculate_ECDF(observed, time_intervals)\n    observed_ECDF['Platform'] = 'Observed'\n\n    # Calculate error\n    error = calculate_loss(simulated_ECDF, observed_ECDF)\n\n    # Append results tuple to list\n    results.append((*params, error))\n\n# Convert results list to DataFrame\nresults_df = pd.DataFrame(results, columns=['a', 'b', 'alpha', 'lambda_', 'loc', 'scale', 'c', 'd', 'l', 's', 'cf', 'df', 'lf', 'sf', 'Error'])\n\nprint(results_df)\n'''","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":205},"id":"6W3rf0OdImY1","outputId":"7bb7fdb1-0d59-4bda-dd26-ccedbdbbdb0d","trusted":true},"execution_count":null,"outputs":[]}]}